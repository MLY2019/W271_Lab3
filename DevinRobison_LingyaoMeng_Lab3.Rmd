---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Group Lab 3'
author: 'Devin Robison and Lingyao Meng'
geometry: margin=1in
output:
  pdf_document:
    latex_engine: xelatex
  number_sections: yes
  html_document: default
  toc: yes
fontsize: 11pt
---

# U.S. traffic fatalities: 1980-2004

1. (30%) Load the data. Provide a description of the basic structure of the dataset, as we have done throughout the semester. Conduct a very thorough EDA, which should include both graphical and tabular techniques, on the dataset, including both the dependent variable *totfatrte* and the potential explanatory variables. You need to write a detailed narrative of your observations of your EDA. 
```{r message=FALSE, warning=TRUE, include=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Load libraries
library(car)
library(dplyr)
library(Hmisc)
library(ggplot2)
library(lattice)
library(plm)
library(ggpubr)
library(gridExtra)
library(corrplot)
library(reshape)
```
```{r}
# load the RData file
load("driving.RData", f <- new.env())
# variable descriptions
# f$desc     
# get the data
driving <- f$data     
str(driving)
```
From Wooldridge's rdata description \
(`https://rdrr.io/cran/wooldridge/man/driving.html`) \
------

sl55: speed limit == 55 \
sl65: speed limit == 65 \
sl70: speed limit == 70 \
sl75: speed limit == 75 \
slnone: no speed limit \
seatbelt: =0 if none, =1 if primary, =2 if secondary \
minage: minimum drinking age \
zerotol: zero tolerance law \
gdl: graduated drivers license law \
bac10: blood alcohol limit .10 \
bac08: blood alcohol limit .08 \
perse: administrative license revocation (per se law) \
totfat: total traffic fatalities \
nghtfat: total nighttime fatalities \
wkndfat: total weekend fatalities \
totfatpvm: total fatalities per 100 million miles \
nghtfatpvm: nighttime fatalities per 100 million miles \
wkndfatpvm: weekend fatalities per 100 million miles \
statepop: state population \
totfatrte: total fatalities per 100,000 population \
nghtfatrte: nighttime fatalities per 100,000 population \
wkndfatrte: weekend accidents per 100,000 population \
vehicmiles: vehicle miles traveled, billions \
unem: unemployment rate, percent \
perc14_24: percent population aged 14 through 24 \
sl70plus: sl70 + sl75 + slnone \
sbprim: =1 if primary seatbelt law \
sbsecon: =1 if secondary seatbelt law \

-----

The dataset has 1200 observations of 56 variables. The response variables are traffic fatalities. The explanatory variables include the year dummies, traffic laws enforcement dummies and some geographic and economic factors. 

The response variable we are interested in is the total fatality rate and the potential explanatory variables include the year dummies, the blood alcohol concentration (BAC) limits, the seatbelt laws, the speed limit of 70 and up, the *per se* law, the graduated drivers license law, the unemployment rate, the percent population aged 14 to 24 and the vehicle miles traveled per capita.

```{r}
summary(driving[c('totfatrte','bac08','bac10','sbprim','sbsecon','sl70plus',
                  'perse','gdl','unem','perc14_24','vehicmilespc')])
```
No irregular values were observed from these variables.

### Univariate analysis of the response variable
```{r fig.width = 3, fig.height = 2, message = FALSE}
ggplot(driving, aes(x = totfatrte)) +
  geom_histogram(aes(y = ..density..), binwidth = 1, fill="#0072B2", colour="black")
```
```{r fig.width = 9, fig.height = 4.5, message = FALSE}
ggplot(driving, aes(x = year, y = totfatrte, color = factor(state))) +
  geom_point() + geom_smooth(method=lm, se=FALSE)
ggplot(driving, aes(factor(state), totfatrte)) +
  geom_boxplot(aes(fill = factor(state)))
```

The distribution of the response variable *totfatrte* is slightly right skewed. Since the skewness is not very serious, we decided not to perform transformation on it. From the time plot grouped by state, we could see that for most states, the fatality rate trended to decrease from 1980 to 2004.  From the boxplot, we observed variated data variances across states.

### Univariate analysis of the explanatory variables
```{r fig.width = 10, fig.height = 15, message = FALSE}
uni.bac08 <- qplot(x = year, y = bac08, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.bac10 <- qplot(x = year, y = bac10, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.sbprim <- qplot(x = year, y = sbprim, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.sbsecon <- qplot(x = year, y = sbsecon, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.perse <- qplot(x = year, y = perse, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.sl70plus <- qplot(x = year, y = sl70plus, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.gdl <- qplot(x = year, y = gdl, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.unem <- qplot(x = year, y = unem, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.perc14_24 <- qplot(x = year, y = perc14_24, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.vehicmilespc <- qplot(x = year, y = vehicmilespc, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
ggarrange(uni.bac08, uni.bac10, uni.sbprim, uni.sbsecon, uni.perse, uni.sl70plus, uni.gdl, uni.unem, 
          uni.perc14_24, uni.vehicmilespc, ncol=2, nrow=5, common.legend = TRUE, legend="bottom")
```

From the time plots, we see the enforcement of BAC limit of 0.08% increased by time, for quite a few states. In fact, over 75% of the observations valued 0 in *bac08*. On the other hand, comparable increasing and decreasing trends were observed on the enforcement of BAC limit of 0.10%, indicating that the enforcement of two limits may not be mutually exclusive. Both variables need to be kept in the model.

The time plot showed that the enforcement of the primary seat belt law trended to increase from 1980 to 2004 for a few states. Similar to *bac08*, over 75% of the observations valued 0 in *sbprim*. In quite a few states, we observed increase trend for the enforcement of the second seat belt law. There were some states where the trend was decrease though.

In most states, the enforcement of the "Per se" law trended to increase from 1980 to 2004. There are also some states where the law remained in effect or never in effect in the period. In a few states, the enforcement of speed limit of 70 and up trended to increase from 1980 to 2004. Some states had never enacted such high speed limit in the period. In fact, over 75% observations valued 0 in *sl70plus*. In a few states, the enforcement of the graduated drivers license law trended to increase from 1980 to 2004. Some states had never enacted the law in the period. In fact, over 75% observations valued 0 in *gdl*.

In most states, the unemployment rate and the percent population aged 14 to 24 trended to decrease from 1980 to 2004.
In most states, the vehicle miles traveled per capita trended to increase from 1980 to 2004.

### Bivariate analysis by state
```{r fig.width = 10, fig.height = 15, message = FALSE}
bi.bac08.state <- qplot(x = bac08, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.bac10.state <- qplot(x = bac10, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.sbprim.state <- qplot(x = sbprim, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sbsecon.state <- qplot(x = sbsecon, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.perse.state <- qplot(x = perse, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sl70plus.state <- qplot(x = sl70plus, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.gdl.state <- qplot(x = gdl, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.unem.state <- qplot(x = unem, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.perc14_24.state <- qplot(x = perc14_24, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.vehicmilespc.state <- qplot(x = vehicmilespc, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
ggarrange(bi.bac08.state, bi.bac10.state, bi.sbprim.state, bi.sbsecon.state, bi.perse.state, 
          bi.sl70plus.state, bi.gdl.state, bi.unem.state, bi.perc14_24.state, bi.vehicmilespc.state, 
          ncol=2, nrow=5, common.legend = TRUE, legend="bottom")
```

### Bivariate analysis by the year
```{r fig.width = 10, fig.height = 15, message = FALSE}
bi.bac08.year <- qplot(x = bac08, y = totfatrte, data = driving, color = factor(year)) + 
  geom_smooth(method=lm, se=FALSE)
bi.bac10.year <- qplot(x = bac10, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.sbprim.year <- qplot(x = sbprim, y = totfatrte, data = driving, color = factor(year)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sbsecon.year <- qplot(x = sbsecon, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.perse.year <- qplot(x = perse, y = totfatrte, data = driving, color = factor(year)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sl70plus.year <- qplot(x = sl70plus, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.gdl.year <- qplot(x = gdl, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.unem.year <- qplot(x = unem, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.perc14_24.year <- qplot(x = perc14_24, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.vehicmilespc.year <- qplot(x = vehicmilespc, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
ggarrange(bi.bac08.year, bi.bac10.year, bi.sbprim.year, bi.sbsecon.year, bi.perse.year, 
          bi.sl70plus.year, bi.gdl.year, bi.unem.year, bi.perc14_24.year, bi.vehicmilespc.year, 
          ncol=2, nrow=5, common.legend = TRUE, legend="bottom")
```

Within states, some negative correlation was observed between *bac08* and *totfatrte*. Within a year, the correlation is not very obvious. This suggests that for a given state, the enforcement of BAC limit of 0.08% would probably decrease the fatality rate. However, there are other effects than *bac08* in explanation of different fatality rates in a year among states.

On the other hand, the correlation between *bac10* and *totfatrte* within states is not very clear. Within a year, some negative correlation was observed.

Within states, negative correlations were observed between both the primary and the secondary seatbelt law and the fatality rate. Within a year, the correlation between *sbprim* and *totfatrte* is still negative but that between *sbsecon* and *totfatrte* is mixed. 

The enforcement of the "Per se" laws was negatively correlated with the fatality rate for most states, with few exceptions. However, within a year, the correlation seems to be wealy positive. 

Interestingly, we observed negative correlation within states between high speed limit (70 and up) and the fatality rate and positive correlation within a year. This suggests complicated effects of *sl70plus* on *totfatrte*. 

Negative correlations were observed between the enforcement of graduated drivers license law and the fatality rate, both across states and across years.

Virtually, for most states, the unemployment rate is positively correlated with the fatality rate while negative correlations were also observed for a few states. The regression lines have variated slopes among states. Similar correlation between *unem* and *totfatrte* was observed within a year.

Virtually, for most states, the percent population aged 14 to 24 is positively correlated with the fatality rate while negative correlations were also observed for a few states. The regression lines have variated slopes among states. Similar correlation between *unem* and *totfatrte* was observed within a year.

Clearly, within a year, *vehicmilespc* and *totfatrte* is positively correlated. On the other hand, the within states correlation seems to be negative for most states. Meanwhile, we observed the cross states regression slopes get decreased by year. It suggests that the positive effect of *vehicmilespc* on *totfatrte* shrinks over time. This may explain the negative within state correlation as there are other factors dereasing the fatality rate.

```{r  fig.width=9, fig.height=5}
df.traffic <- as.data.frame(f$data)
rbind(head(df.traffic,5), tail(df.traffic, 5))

# Create a restricted data set that doesn't include year dummies for analysis with reduced spam.
df.traffic.restricted <- df.traffic %>%
  select(!matches("d[0-9]{2}"))

# This dumps too much for inclusion in knit
#describe(df.traffic.restricted)

df.traffic.means <- df.traffic.restricted %>%
  group_by(year) %>%
  summarise_at(vars(totfatrte, vehicmilespc, nghtfatrte, wkndfatrte), list(mean=mean)) 
df.traffic.means
  
# Our ultimate question revolves around the relationship between traffic laws and total fotality rate
#   so lets take a look at how the fatality rates have changed over time to get a feel for years where
#   we might have had changes.

# Fatality rate's by state
ggplot(df.traffic) +
  aes(as.factor(state), totfatrte) +
  geom_boxplot() + geom_jitter(width = 0.2) + ggtitle('Fatality Rates by State')

# Pooled fatality rate's by year
ggplot(df.traffic) +
  aes(as.factor(year), totfatrte) +
  geom_boxplot() +
    geom_jitter(width = 0.2) + ggtitle('Fatality Rates by Year') +
  geom_smooth(data=df.traffic.means, aes(x=as.factor(year), y=totfatrte_mean, group=2), color='blue')

ggplot(df.traffic) +
  aes(as.factor(year), nghtfatrte) +
  geom_boxplot() +
    geom_jitter(width = 0.2) + ggtitle('Night Fatality Rates by Year') +
  geom_smooth(data=df.traffic.means, aes(x=as.factor(year), y=nghtfatrte_mean, group=2), color='blue')

ggplot(df.traffic) +
  aes(as.factor(year), wkndfatrte) +
  geom_boxplot() +
    geom_jitter(width = 0.2) + ggtitle('Weekend Fatality Rates by Year') +
  geom_smooth(data=df.traffic.means, aes(x=as.factor(year), y=wkndfatrte_mean, group=2), color='blue')

ggplot(df.traffic) +
  aes(as.factor(year), vehicmilespc) +
  geom_boxplot() +
    geom_jitter(width = 0.2) + ggtitle('Total Miles Driven - Per Capita') +
  geom_smooth(data=df.traffic.means, aes(x=as.factor(year), y=vehicmilespc_mean, group=1), color='blue')
```

```{r fig.width=9, fig.height=5}
# Take a look at overall correlations with specific laws. Since law variables are binary, we can think of their average as something 
# like an adoption rate across states in a given year.
df.traffic.law.means <- df.traffic.restricted %>%
  group_by(year) %>%
  mutate(perc14_24 = perc14_24 / 100) %>%
  mutate(unem = unem / 100) %>%
  summarise_at(vars(totfatrte,
                    bac08, bac10, perse, sbprim, sbsecon, sl70plus, gdl), list(mean=mean)) 

df.traffic.adoption <- as.data.frame(df.traffic.law.means)

df.traffic.law.melt <- melt(df.traffic.adoption, id.vars=c('year', 'totfatrte_mean'))

ggplot(df.traffic.law.melt) +
  aes(value, totfatrte_mean, col=variable) +
  geom_line() +
  facet_wrap(~variable) + 
  labs(title="Mean Total Fatality Rate as a Function of Law Adoption Percentage")

corrmat <- cor(df.traffic.law.means)
corrplot(corrmat, method='ellipse', type='upper')
```
Examining a correlation plot of our fatality rate mean along with the means of our law indicator variables, which act as a proxy for adoption rate across all 50 states, it appears as though there is negative correlation in a bi-variate sense for each of the indicated laws. 


2. (15%) How is the our dependent variable of interest *totfatrte* defined? What is the average of this variable in each of the years in the time period covered in this dataset? Estimate a linear regression model of *totfatrte* on a set of dummy variables for the years 1981 through 2004. What does this model explain? Describe what you find in this model. Did driving become safer over this period? Please provide a detailed explanation.

```{r}
# Average totfatrate by year
df.traffic.means

# Extract dummies
df.traffic.dummies <- df.traffic %>%
  filter(year > 1980 ) %>%
  select(!matches('d80')) %>%
  select(matches("totfatrte") | matches("d[0-9]{2}"))
#df.traffic.dummies

lm.yr.dummie.fit <- lm(df.traffic.dummies)
#lm.yr.dummie.fit

summary(lm.yr.dummie.fit)
```

This model estimates the linear intercept for the pooled fatality rates across states, with a different intercept for each year. Quite interestingly, we see the dummy variables for 1981-1990 are at least marginally significant, an observation that appears correlated with the leveling off of the mean fatality rate across states, observed in the `Fatality rates by year` graph generated in question (1).

Given this model and the referenced graph from (1), it does appear that if we interpret a drop in totfatrte as 'driving becoming safer', then there does seem to be a general trend in that direction; additionally and without asserting any specific cause, it does appear that something(s) occurred in the 1981 to 1990 time frame that is strongly correlated with a decrease in fatality rates. Additionally, we can also observe from the `Total Miles Driven - Per Capita` graph, that the total miles being driven, per person, have gone up steadily over the same time period which, implicitly, would create more opportunities for fatal incidents to occur.

3. (15%) Expand your model in *Exercise 2* by adding variables *bac08, bac10, perse, sbprim, sbsecon, sl70plus, gdl, perc14_24, unem, vehicmilespc*, and perhaps *transformations of some or all of these variables*. Please explain carefully your rationale, which should be based on your EDA, behind any transformation you made. If no transformation is made, explain why transformation is not needed. How are the variables *bac8* and *bac10* defined? Interpret the coefficients on *bac8* and *bac10*. Do *per se laws* have a negative effect on the fatality rate? What about having a primary seat belt law? (Note that if a law was enacted sometime within a year the fraction of the year is recorded in place of the zero-one indicator.)

The variables *bac08, bac10, perse, subprim, sbsecon, sl70plus, gdl* have value ranges from 0 to 1. In fact these are binary indicators of whether certain law was in effect in a state, in a year. The decimal values, if there is any, stand for the fraction of the year when the law was enacted within a year. The variables *perc14_24*, *unem* and *vehicmilespc* are continuous and the distributions are not severly skewed. Also, we didn't observed any obvious non-linear relationship between any explanatory variable and the response variable. Therefore, no transformation is needed for either variable.

```{r}
lm2 <- lm(data = driving, totfatrte ~ d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + 
            d91 + d92 + d93 + d94 + d95 + d96 + d97 + d98 + d99 + d00 + d01 + d02 + d03 + d04 + 
            bac08 + bac10 + perse + sbprim + sbsecon + sl70plus + gdl + perc14_24 + unem + vehicmilespc)

summary(lm2)
```

The variable *bac08* is the binary indicator of whether the blood alcohol concentration (BAC) of 0.08% was allowed in a state, in a year. The variable *bac10* is the binary indicator of whether the blood alcohol concentration of 0.10% was allowed in a state, in a year. 

The coefficient of *bac08* was estimated as -2.5. It means that holding all other conditions constant, when the BAC limit of 0.08% was enforced, the total fatality rate would drop by 2.5. The coefficient of *bac10* was estimated as -1.4. It means that holding all other conditions constant, when the BAC limit of 0.10% was enforced, the total fatality rate would drop by 1.4. Clearly, the effect of imposing BAC limit of 0.08% was estimated to be larger than that of 0.10%, in decreasing the total fatality rate.

The coefficient of *perse* was estimated as -0.062 and the p-value is smaller than 0.05. There is marginal evidence to claim that the effect of *perse* on the total fatality rate is negative. On the other hand, the t-test for the coefficient of *sbprim* resulted in a quite large p-value, so there is a lack of evidence to claim that *sbprim* has effect on the total fatality rate.

4. (15%) Reestimate the model from *Exercise 3* using a fixed effects (at the state level) model. How do the coefficients on *bac08, bac10, perse, and sbprim* compare with the pooled OLS estimates? Which set of estimates do you think is more reliable? What assumptions are needed in each of these models?  Are these assumptions reasonable in the current context?

```{r}
driving.panel <- pdata.frame(driving, c('state', 'year'))

fe <- plm(data = driving.panel, 
          totfatrte ~ d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + d91 + d92 + d93 + 
            d94 + d95 + d96 + d97 + d98 + d99 + d00 + d01 + d02 + d03 + d04 + bac08 + bac10 + 
            perse + sbprim + sbsecon + sl70plus + gdl + perc14_24 + unem + vehicmilespc, 
          model = 'within')

summary(fe)
```
```{r}
data.frame('Pooled.OLS' = coefficients(lm2)[c('bac08', 'bac10', 'perse', 'sbprim')],
           'Fixed.effects' = coefficients(fe)[c('bac08', 'bac10', 'perse', 'sbprim')])
```
The estimated coefficients of *bac08, bac10, perse, and sbprim* by pooled OLS and fixed effects are listed as above. All coefficients were estimated as negative, by either model. Compared to those estimated by pooled OLS, the coefficients of *bac08* and *bac10* estimated by fixed effects got smaller in the absolute values. On the other hand, the estimated coefficients of *perse* and *sbprim* got larger. Further, *sbprim* was not statistically significant when estimated by pooled OLS, but was statistically significant when estimated by fixed effects, at 5% level.

The validity of the pooled OLS model depends on the satisfaction of the CLM assumptions of:
1. Linear in parameters;
2. Random sampling;
3. No perfect collinearity;
4. Zero conditional mean;
5. Homoskedasticity;
6. Normality.

Under the current context, CLM assumption 4, 5 and 6 can hardly be satisfied when then unobserved effects are correlated with the explanatory variables. For example, drug abuse rate could be an unoberved effect for the total fatality rate and it could be correlated with unemployment rate and the percent population aged 14 to 24. 

The assumptions for the fixed effects model are as follows:

1. For each i, the model is 
$$ y_{it} = \beta_1 x_{it1} + ... + \beta_k x_{itk} + a_i + u_{it}, t = 1,...,T,$$ 
where the $\beta_j$ are the parameters to estimate and $a_i$ is the unobserved effect.

2. Random sampling from the cross section.

3. Each explanatory variable changes over time and no perfect collineartiy.

4. $E(u_{it} | X_i, a_i) = 0$

5. $Var(u_{it} | X_i, a_i) = VAR(u_{it}) = \sigma^2_u, for \ all \ t = 1,...,T$

6. $Cov(u_{it}, u_{is} | X_i, a_i) = 0$

7. Conditional on $X_i$ and $a_i$, the $u_{it}$ are independent and identically distributed as $Normal(0, \sigma^2_u)$.

The fixed effects model allows for arbitrary correlation between $a_i$ and $X_i$ in any time period. Under the current context, we don't see serious violations to these assumptions. Therefore, the coefficients estimated by fixed effects are more reliable.

5. (10%) Would you perfer to use a random effects model instead of the fixed effects model you built in *Exercise 4*? Please explain.

Lets start by estimating a random effects model for the same dataset.

```{r}
rnd_e <- plm(data = driving.panel, 
          totfatrte ~ d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + d91 + d92 + d93 + 
            d94 + d95 + d96 + d97 + d98 + d99 + d00 + d01 + d02 + d03 + d04 + bac08 + bac10 + 
            perse + sbprim + sbsecon + sl70plus + gdl + perc14_24 + unem + vehicmilespc, 
          model = 'random')

summary(rnd_e)
```

If we examine the predicted coeficients for our fixed effect model, compared with a random effects model, in a similar fashion to what was done in (4), we obtain the following:

```{r}

data.frame('Fixed.effects' = coefficients(fe)[c('bac08', 'bac10', 'perse', 'sbprim')],
           'Random.effects' = coefficients(rnd_e)[c('bac08', 'bac10', 'perse', 'sbprim')])
```

This indicates that the overall predictions provided by the random effects model are in close agreement with the fixed effects model. Given that this is the case, if we want to decide which model is more appropriate, we should consider the assumptions associated with each model. A major downside to our random effects model is that we must we willing to make the very strong assumption that our unobserved errors are uncorrelated with any of our explanatory variables: an extremely dubious assumption in this case. Given that both our tests produce similar model coefficients, selecting the fixed effects model seems like the correct choice on the surface.

A more structured approach, as suggested by Wooldridge, is to utilize the Hausman test for panel data, under which a rejection of the null hypothesis indicates that there is not sufficient evidence to believe that our unobserved effects are uncorrelated with our explanatory variables.

```{r}
phtest(fe, rnd_e)
```
The results of the Hausman test are quite stark, with an extremely small p-value, indicating that we should strongly prefer the fixed effects model.

6. (10%) Suppose that *vehicmilespc*, the number of miles driven per capita, increases by $1,000$. Using the FE estimates, what is the estimated effect on *totfatrte*? Please interpret the estimate.

```{r}
round(coefficients(fe)['vehicmilespc'] * 1000, 0)
```
Holding all other conditions constant, with the number of miles driven per catipa increased by 1,000, the total fatalities per 100,000 population would increase by 1.

7. (5%) If there is serial correlation or heteroskedasticity in the idiosyncratic errors of the model, what would be the consequences on the estimators and their standard errors?

In terms of the fixed effect model, if we have serial correlation and/or heteroskedasticity in our idiosyncratic error, it generally means that we have failed to include some important time varying term, and in so doing we have violated the strictly exogenous assumption required for the model. In the case where these assumptions are violated, then standard errors and test statistics are likely invalid.

Woolridge asserts (pg.421) that it is possible to correct for serial correlation and heteroskedacity when N >> T, and N >> 1; but, then goes on to indicate that such an approach is outside the scope of the current text, so we will assume for our situation that this is the case.

In the simplifed case, where we have heteroskedacity in our idiosyncratic error without any serial correlation, we can utilize previously discussed techniques for generating robust standard errors to obtain appropriate statistics.












