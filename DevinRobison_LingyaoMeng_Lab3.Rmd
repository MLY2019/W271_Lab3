---
title: 'Statistical Methods for Discrete Response, Time Series, and Panel Data (W271): Group Lab 3'
author: 'Devin Robison and Lingyao Meng'
geometry: margin=1in
output:
  pdf_document:
    latex_engine: xelatex
  number_sections: yes
  html_document: default
  toc: yes
fontsize: 11pt
---

# U.S. traffic fatalities: 1980-2004

1. (30%) Load the data. Conduct a very thorough EDA.
```{r message=FALSE, warning=TRUE, include=FALSE}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)

# Load libraries
library(car)
library(dplyr)
library(Hmisc)
library(ggplot2)
library(lattice)
library(plm)
library(ggpubr)
library(gridExtra)
library(corrplot)
library(reshape)
```
```{r}
# load data
load("driving.RData", f <- new.env())
driving <- f$data     
str(driving)
```
For a full variable description, see Wooldridge: `https://rdrr.io/cran/wooldridge/man/driving.html` 
The dataset has 1200 observations of 56 variables, including the traffic fatalities, the year dummies, traffic laws enforcement dummies and the related geographic and economic factors. The response variable we are interested in is the total fatality rate and the potential explanatory variables include the year dummies, the blood alcohol concentration (BAC) limits, the seatbelt laws, the speed limit of 70 and up, the *per se* law, the graduated drivers license law, the unemployment rate, the percent population aged 14 to 24 and the vehicle miles traveled per capita.
```{r fig.width = 9, fig.height = 4, message = FALSE}
# Create a restricted data set that doesn't include year dummies for analysis with reduced spam.
driving.restricted <- driving %>% select(!matches("d[0-9]{2}"))
driving.means <- driving.restricted %>% group_by(year) %>%
  summarise_at(vars(totfatrte, vehicmilespc, nghtfatrte, wkndfatrte), list(mean=mean)) 
# Pooled fatality rate's by year
ggplot(driving) + aes(as.factor(year), totfatrte) + geom_boxplot() +
  geom_jitter(width = 0.2) + ggtitle('Fatality Rates by Year') +
  geom_smooth(data=driving.means, aes(x=as.factor(year), y=totfatrte_mean, group=2, color='blue')) +
  geom_smooth(data=driving.means, aes(x=as.factor(year), y=nghtfatrte_mean, group=2, color='green')) +
  geom_smooth(data=driving.means, aes(x=as.factor(year), y=wkndfatrte_mean, group=2, color='red')) +
  scale_colour_manual(name = 'Fatality Type', 
         values =c('blue'='blue','green'='green', 'red'='red'), labels = c('Total', 'Night', 'Weekend'))
ggplot(driving) + aes(as.factor(year), vehicmilespc) + geom_boxplot() +
  geom_jitter(width = 0.2) + ggtitle('Total Miles Driven - Per Capita') +
  geom_smooth(data=driving.means, aes(x=as.factor(year), y=vehicmilespc_mean, group=1), color='blue')
``` 

From the above graph `Fatality Rates by Year` in conjunction with `Total Miles Driver Per-Capita`, we can see that, without any assertion of causality, that overall fatality rates, as well as night and weekend fatality rates have steadily decreased over our time period of interest, while the number of miles driven per-capita has steadily increased. This provides substantial credibility to the hypothesis that driven has become safter, and should give us confidence in investigating potential causes.

### Univariate analysis of the response variable
```{r fig.width = 12, fig.height = 3, message = FALSE}
p1 <- ggplot(driving, aes(x = totfatrte)) +
      geom_histogram(aes(y = ..density..), binwidth = 1, fill="#0072B2", colour="black")
p2 <- ggplot(driving, aes(factor(state), totfatrte)) +
      geom_boxplot(aes(fill = factor(state))) + ggtitle('Total fatality rate by state')
ggarrange(p1, p2, ncol=2, nrow=1, widths=c(3, 9), legend="none")
```
```{r fig.width = 9, fig.height = 4.5, message = FALSE}
ggplot(driving, aes(x = year, y = totfatrte, color = factor(state))) +
  geom_point() + geom_smooth(method=lm, se=FALSE) + ggtitle('Total fatality rate by year')
```

The distribution of the response variable *totfatrte* is slightly right skewed. Since the skewness is not very serious, we decided not to perform transformation on it. From the box plot, we observed variated data variances across states. From the time plot grouped by state, we could see that for most states, the fatality rate trended to decrease from 1980 to 2004. 

### Univariate analysis of the explanatory variables
```{r fig.width = 9, fig.height = 2, message = FALSE}
hist.unem <- ggplot(driving, aes(x = unem)) +
             geom_histogram(aes(y = ..density..), binwidth = 0.5, fill="#0072B2", colour="black")
hist.perc <- ggplot(driving, aes(x = perc14_24)) +
             geom_histogram(aes(y = ..density..), binwidth = 0.5, fill="#0072B2", colour="black")
hist.vmpc <- ggplot(driving, aes(x = vehicmilespc)) +
             geom_histogram(aes(y = ..density..), binwidth = 500, fill="#0072B2", colour="black")
ggarrange(hist.unem, hist.perc, hist.vmpc, ncol=3, nrow=1)
```

The distributions of unemployment rate, percent population aged 14 to 24 and vehicle miles driven per capita are all right-skewed. The skewness of *perc14_24* is more severe.
```{r fig.width = 12, fig.height = 12, message = FALSE}
uni.bac08 <- qplot(x = year, y = bac08, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.bac10 <- qplot(x = year, y = bac10, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.sbprim <- qplot(x = year, y = sbprim, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.sbsecon <- qplot(x = year, y = sbsecon, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.perse <- qplot(x = year, y = perse, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.sl70plus <- qplot(x = year, y = sl70plus, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.gdl <- qplot(x = year, y = gdl, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.unem <- qplot(x = year, y = unem, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
uni.perc14_24 <- qplot(x = year, y = perc14_24, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
uni.vehicmilespc <- qplot(x = year, y = vehicmilespc, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
ggarrange(uni.bac08, uni.bac10, uni.sbprim, uni.sbsecon, uni.perse, uni.sl70plus, uni.gdl, uni.unem, 
          uni.perc14_24, uni.vehicmilespc, ncol=3, nrow=4, common.legend = TRUE, legend="bottom")
```

From the time plots, we see the enforcement of BAC limit of 0.08% increased by time, for quite a few states. In fact, over 75% of the observations valued 0 in *bac08*. On the other hand, comparable increasing and decreasing trends were observed on the enforcement of BAC limit of 0.10%, indicating that the enforcement of two limits may not be mutually exclusive. Both variables need to be kept in the model.

The enforcement of the primary seat belt law trended to increase from 1980 to 2004 for a few states. Similar to *bac08*, over 75% of the observations valued 0 in *sbprim*. In quite a few states, we observed increase trend for the enforcement of the second seat belt law. There were some states where the trend was decrease though.

In most states, the enforcement of the "Per se" law trended to increase in the period. There are also some states where the law remained in effect or never in effect in the period. In a few states, the enforcement of speed limit of 70 and up trended to increase by time. Some states had never enacted such high speed limit in the period. In fact, over 75% observations valued 0 in *sl70plus*. The enforcement of the graduated drivers license law trended to increase in a few states. Some states had never enacted the law in the period. In fact, over 75% observations valued 0 in *gdl*.

In most states, the unemployment rate and the percent population aged 14 to 24 trended to decreas while the trend vehicle miles traveled per capita was increase.

### Initial analysis of the effcts of the law indicators on the fatality rate
```{r fig.width=9, fig.height=4}
# Take a look at overall correlations with specific laws. Since law variables are binary, we can think of their average as something like an adoption rate across states in a given year.
driving.law.means <- driving.restricted %>% group_by(year) %>%
  mutate(perc14_24 = perc14_24 / 100) %>% mutate(unem = unem / 100) %>%
  summarise_at(vars(totfatrte, bac08, perse, sbprim, sbsecon, sl70plus, gdl), list(mean=mean)) 
driving.adoption <- as.data.frame(driving.law.means)
driving.law.melt <- melt(driving.adoption, id.vars=c('year', 'totfatrte_mean'))
ggplot(driving.law.melt) +
  aes(value, totfatrte_mean, col=variable) + geom_line() + facet_wrap(~variable) + 
  labs(title="Mean Total Fatality Rate as a Function of Law Adoption Percentage")
```

The above plot uses the mean of the binary indicator for a given law, provided by each state, as a proxy for the total adoption of the law across all states. For example, if no state has implemented the law in a given year, then the mean will be 0, if all states have adopted the law, it will be 1, otherwise it will be equal to $adoption\_rate(law) = \frac{1}{N} \cdot \sum_{i=1}^{N}{I[law_{i} == 1]}$, where I is the indicator function. If we plot total fatality rate as a function of law adoption rate, we might be able to observe something interesting.

In fact, we do observe some interesting correlation's between our total fatality rate and our proxy for adoption rate, indicating that there is reason to believe that adoption of certain laws, such as the `perse` law, does improve driver safety.

### Bivariate analysis by state
```{r fig.width = 12, fig.height = 12, message = FALSE}
bi.bac08.state <- qplot(x = bac08, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.bac10.state <- qplot(x = bac10, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.sbprim.state <- qplot(x = sbprim, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sbsecon.state <- qplot(x = sbsecon, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.perse.state <- qplot(x = perse, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sl70plus.state <- qplot(x = sl70plus, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.gdl.state <- qplot(x = gdl, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.unem.state <- qplot(x = unem, y = totfatrte, data = driving, color = factor(state)) + 
  geom_smooth(method=lm, se=FALSE)
bi.perc14_24.state <- qplot(x = perc14_24, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
bi.vehicmilespc.state <- qplot(x = vehicmilespc, y = totfatrte, data = driving, color = factor(state)) +
  geom_smooth(method=lm, se=FALSE)
ggarrange(bi.bac08.state, bi.bac10.state, bi.sbprim.state, bi.sbsecon.state, bi.perse.state, 
          bi.sl70plus.state, bi.gdl.state, bi.unem.state, bi.perc14_24.state, bi.vehicmilespc.state, 
          ncol=3, nrow=4, common.legend = TRUE, legend="bottom")
```

Within states, some negative correlation was observed between *bac08* and *totfatrte*. This suggests that for a given state, the enforcement of BAC limit of 0.08% would probably decrease the fatality rate. On the other hand, the correlation between *bac10* and *totfatrte* is not very clear. Negative correlations were observed between both the primary and the secondary seatbelt law and the fatality rate. The enforcement of the "Per se" laws was negatively correlated with the fatality rate for most states, with few exceptions. Negative effects were also observed on high speed limit (70 and up) and the enforcement of graduated drivers license law.

Virtually, for most states, the unemployment rate is positively correlated with the fatality rate with variated slopes among states. Similar effect was observed on the percent population aged 14 to 24. For vehicle miles driven per capita, the within states correlation seems to be negative for most states.

### Bivariate analysis by the year
```{r fig.width = 12, fig.height = 10, message = FALSE}
bi.bac08.year <- qplot(x = bac08, y = totfatrte, data = driving, color = factor(year)) + 
  geom_smooth(method=lm, se=FALSE)
bi.bac10.year <- qplot(x = bac10, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.sbprim.year <- qplot(x = sbprim, y = totfatrte, data = driving, color = factor(year)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sbsecon.year <- qplot(x = sbsecon, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.perse.year <- qplot(x = perse, y = totfatrte, data = driving, color = factor(year)) + 
  geom_smooth(method=lm, se=FALSE)
bi.sl70plus.year <- qplot(x = sl70plus, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.gdl.year <- qplot(x = gdl, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.unem.year <- qplot(x = unem, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.perc14_24.year <- qplot(x = perc14_24, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
bi.vehicmilespc.year <- qplot(x = vehicmilespc, y = totfatrte, data = driving, color = factor(year)) +
  geom_smooth(method=lm, se=FALSE)
ggarrange(bi.bac08.year, bi.bac10.year, bi.sbprim.year, bi.sbsecon.year, bi.perse.year, 
          bi.sl70plus.year, bi.gdl.year, bi.unem.year, bi.perc14_24.year, bi.vehicmilespc.year, 
          ncol=3, nrow=4, common.legend = TRUE, legend="bottom")
```

Within a year, the correlation between *bac08* and *totfatrte* is not very obvious. On the other hand, some negative correlation was observed between *bac10* and *totfatrte*. The within years correlation between *sbprim* and *totfatrte* is also negative but that between *sbsecon* and *totfatrte* is mixed. Interestingly, some weakly positive effect was observed from *perse* while the positive effect was more obvious from *sl70plus*. This indicates that the effects of the enforcement of the "per se" law and high speed limit are complicated. Negative effect was observed from *gdl*. 

In most years, *unem* were found positively correlated with *totfatrte* with variated regression slopes among years. Similar effects were also observed from *perc14_24* and *vehicmilespc*. For *vehicmilespc*, the regression slopes get decreased by year. It suggests that the positive effect of *vehicmilespc* on *totfatrte* shrinks over time. This may explain the seemingly negative within state correlation as there are other factors dereasing the fatality rate.

2. (15%) How is the our dependent variable of interest *totfatrte* defined? What is the average of this variable in each of the years in the time period covered in this dataset? Estimate a linear regression model of *totfatrte* on a set of dummy variables for the years 1981 through 2004. What does this model explain? Did driving become safer over this period? 

Total fatality rate is defined as the number of fatalities per 100,000 population. The rounded year based means are as below.

```{r}
# Average totfatrate by year
t(round(driving.means[c('year', 'totfatrte_mean')], 0))
# Extract dummies
driving.dummies <- driving %>% filter(year > 1980 ) %>%
  select(!matches('d80')) %>% select(matches("totfatrte") | matches("d[0-9]{2}"))
lm.yr.dummie.fit <- lm(driving.dummies)
summary(lm.yr.dummie.fit)
```

The linear regression on the year dummies were estimated as above. This model estimates the linear intercept for the pooled fatality rates across states, with a different intercept for each year. Quite interestingly, we see the dummy variables for 1981-1990 are at least marginally significant, an observation that appears correlated with the leveling off of the mean fatality rate across states, observed in the `Fatality rates by year` graph generated in question (1).

Given this model and the referenced graph from (1), it does appear that if we interpret a drop in totfatrte as 'driving becoming safer', then there does seem to be a general trend in that direction; additionally and without asserting any specific cause, it does appear that something(s) occurred in the 1981 to 1990 time frame that is strongly correlated with a decrease in fatality rates. Additionally, we can also observe from the `Total Miles Driven - Per Capita` graph, that the total miles being driven, per person, have gone up steadily over the same time period which, implicitly, would create more opportunities for fatal incidents to occur.

3. (15%) Expand your model in *Exercise 2* by adding variables *bac08, bac10, perse, sbprim, sbsecon, sl70plus, gdl, perc14_24, unem, vehicmilespc*, and perhaps *transformations of some or all of these variables*. Please explain carefully your rationale, which should be based on your EDA, behind any transformation you made. If no transformation is made, explain why transformation is not needed. How are the variables *bac8* and *bac10* defined? Interpret the coefficients on *bac8* and *bac10*. Do *per se laws* have a negative effect on the fatality rate? What about having a primary seat belt law? 

The binary variables *bac08, bac10, perse, subprim, sbsecon, sl70plus, gdl* have value ranges from 0 to 1. No transformation is needed for these variables. The variables *perc14_24*, *unem* and *vehicmilespc* are continuous and normalized, but given that the skewness of *perc14_24* is more severed we decided to take logarithmic transformation on it. 

```{r}
lm2 <- lm(data = driving, totfatrte ~ d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + 
            d91 + d92 + d93 + d94 + d95 + d96 + d97 + d98 + d99 + d00 + d01 + d02 + d03 + d04 + 
            bac08 + bac10 + perse + sbprim + sbsecon + sl70plus + gdl + log(perc14_24) + unem + vehicmilespc)
summary(lm2)
```

The variable *bac08* is the binary indicator of whether the blood alcohol concentration (BAC) of 0.08% was allowed in a state, in a year. The variable *bac10* is the binary indicator of whether the blood alcohol concentration of 0.10% was allowed in a state, in a year. 

The coefficient of *bac08* was estimated as -2.5. It means that holding all other conditions constant, when the BAC limit of 0.08% was enforced, the total fatality rate would drop by 2.5. The coefficient of *bac10* was estimated as -1.4. It means that holding all other conditions constant, when the BAC limit of 0.10% was enforced, the total fatality rate would drop by 1.4. Clearly, the effect of imposing BAC limit of 0.08% was estimated to be larger than that of 0.10%, in decreasing the total fatality rate.

The coefficient of *perse* was estimated as -0.062 and the p-value is smaller than 0.05. There is marginal evidence to claim that the effect of *perse* on the total fatality rate is negative. On the other hand, the t-test for the coefficient of *sbprim* resulted in a quite large p-value, so there is a lack of evidence to claim that *sbprim* has effect on the total fatality rate.

4. (15%) Reestimate the model from *Exercise 3* using a fixed effects (at the state level) model. How do the coefficients on *bac08, bac10, perse, and sbprim* compare with the pooled OLS estimates? Which set of estimates do you think is more reliable? What assumptions are needed in each of these models?  Are these assumptions reasonable in the current context?

```{r}
driving.panel <- pdata.frame(driving, c('state', 'year'))
fe <- plm(data = driving.panel, 
          totfatrte ~ d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + d91 + d92 + d93 + 
            d94 + d95 + d96 + d97 + d98 + d99 + d00 + d01 + d02 + d03 + d04 + bac08 + bac10 + 
            perse + sbprim + sbsecon + sl70plus + gdl + log(perc14_24) + unem + vehicmilespc, 
          model = 'within')
summary(fe)
```
```{r}
data.frame('Pooled.OLS' = coefficients(lm2)[c('bac08', 'bac10', 'perse', 'sbprim')],
           'Fixed.effects' = coefficients(fe)[c('bac08', 'bac10', 'perse', 'sbprim')])
```
The estimated coefficients of *bac08, bac10, perse, and sbprim* by pooled OLS and fixed effects are listed as above. All coefficients were estimated as negative, by either model. Compared to those estimated by pooled OLS, the coefficients of *bac08* and *bac10* estimated by fixed effects got smaller in the absolute values. On the other hand, the estimated coefficients of *perse* and *sbprim* got larger. Further, *sbprim* was not statistically significant when estimated by pooled OLS, but was statistically significant when estimated by fixed effects, at 5% level.

The validity of the pooled OLS model depends on the satisfaction of the CLM assumptions of:
1. Linear in parameters;
2. Random sampling;
3. No perfect collinearity;
4. Zero conditional mean;
5. Homoskedasticity;
6. Normality.

Under the current context, CLM assumption 4, 5 and 6 can hardly be satisfied when then unobserved effects are correlated with the explanatory variables. For example, drug abuse rate could be an unoberved effect for the total fatality rate and it could be correlated with unemployment rate and the percent population aged 14 to 24. 

The assumptions for the fixed effects model are as follows:

1. For each i, the model is 
$$ y_{it} = \beta_1 x_{it1} + ... + \beta_k x_{itk} + a_i + u_{it}, t = 1,...,T,$$ 
where the $\beta_j$ are the parameters to estimate and $a_i$ is the unobserved effect.

2. Random sampling from the cross section.

3. Each explanatory variable changes over time and no perfect collineartiy.

4. $E(u_{it} | X_i, a_i) = 0$

5. $Var(u_{it} | X_i, a_i) = VAR(u_{it}) = \sigma^2_u, for \ all \ t = 1,...,T$

6. $Cov(u_{it}, u_{is} | X_i, a_i) = 0$

7. Conditional on $X_i$ and $a_i$, the $u_{it}$ are independent and identically distributed as $Normal(0, \sigma^2_u)$.

The fixed effects model allows for arbitrary correlation between $a_i$ and $X_i$ in any time period. Under the current context, we don't see serious violations to these assumptions. Therefore, the coefficients estimated by fixed effects are more reliable.

5. (10%) Would you perfer to use a random effects model instead of the fixed effects model you built in *Exercise 4*? 

Lets start by estimating a random effects model for the same dataset.
```{r}
rnd_e <- plm(data = driving.panel, 
          totfatrte ~ d81 + d82 + d83 + d84 + d85 + d86 + d87 + d88 + d89 + d90 + d91 + d92 + d93 + 
            d94 + d95 + d96 + d97 + d98 + d99 + d00 + d01 + d02 + d03 + d04 + bac08 + bac10 + 
            perse + sbprim + sbsecon + sl70plus + gdl + log(perc14_24) + unem + vehicmilespc, 
          model = 'random')
summary(rnd_e)
```
If we examine the predicted coeficients for our fixed effect model, compared with a random effects model, in a similar fashion to what was done in (4), we obtain the following:
```{r}
data.frame('Fixed.effects' = coefficients(fe)[c('bac08', 'bac10', 'perse', 'sbprim')],
           'Random.effects' = coefficients(rnd_e)[c('bac08', 'bac10', 'perse', 'sbprim')])
```
This indicates that the overall predictions provided by the random effects model are in close agreement with the fixed effects model. Given that this is the case, if we want to decide which model is more appropriate, we should consider the assumptions associated with each model. A major downside to our random effects model is that we must we willing to make the very strong assumption that our unobserved errors are uncorrelated with any of our explanatory variables: an extremely dubious assumption in this case. Given that both our tests produce similar model coefficients, selecting the fixed effects model seems like the correct choice on the surface.

A more structured approach, as suggested by Wooldridge, is to utilize the Hausman test for panel data, under which a rejection of the null hypothesis indicates that there is not sufficient evidence to believe that our unobserved effects are uncorrelated with our explanatory variables.
```{r}
phtest(fe, rnd_e)
```
The results of the Hausman test are quite stark, with an extremely small p-value, indicating that we should strongly prefer the fixed effects model.

6. (10%) Suppose that *vehicmilespc*, the number of miles driven per capita, increases by $1,000$. Using the FE estimates, what is the estimated effect on *totfatrte*? Please interpret the estimate.

```{r}
round(coefficients(fe)['vehicmilespc'] * 1000, 0)
```
Holding all other conditions constant, with the number of miles driven per catipa increased by 1,000, the total fatalities per 100,000 population would increase by 1.

7. (5%) If there is serial correlation or heteroskedasticity in the idiosyncratic errors of the model, what would be the consequences on the estimators and their standard errors?

In terms of the fixed effect model, if we have serial correlation and/or heteroskedasticity in our idiosyncratic error, it generally means that we have failed to include some important time varying term, and in so doing we have violated the strictly exogenous assumption required for the model. In the case where these assumptions are violated, then standard errors and test statistics are likely invalid.

Woolridge asserts (pg.421) that it is possible to correct for serial correlation and heteroskedacity when N >> T, and N >> 1; but, then goes on to indicate that such an approach is outside the scope of the current text, so we will assume for our situation that this is the case.

In the simplifed case, where we have heteroskedacity in our idiosyncratic error without any serial correlation, we can utilize previously discussed techniques for generating robust standard errors to obtain appropriate statistics.












